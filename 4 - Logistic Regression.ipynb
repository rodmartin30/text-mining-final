{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "K_CLUSTERS = 8\n",
    "K_ITERS = 250\n",
    "\n",
    "MESSAGES_PATH = 'data/text2corpus/corpus_messages.txt'\n",
    "ORIGINAL_MESSAGES_PATH = 'data/text2corpus/corpus_original_messages.txt'\n",
    "\n",
    "import pickle\n",
    "\n",
    "def load_corpus():\n",
    "    pre_data = []\n",
    "    data = []\n",
    "    with open(MESSAGES_PATH, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    with open(ORIGINAL_MESSAGES_PATH, \"rb\") as f:\n",
    "        pre_data = pickle.load(f)\n",
    "\n",
    "    return data, pre_data\n",
    "\n",
    "data, original_data = load_corpus()\n",
    "\n",
    "data_str = [' '.join(lst) for lst in data]\n",
    "#data_feature = pd.read_pickle('data/df_from_bow_tfidf.pkl')\n",
    "#data_feature = pd.read_pickle('data/df_from_doc2vec.pkl')\n",
    "data_feature = pd.read_pickle('data/df_from_mean_fasttext.pkl')\n",
    "#data_feature = pd.read_pickle('data/df_from_sum_fasttext.pkl')\n",
    "\n",
    "def clustering(vector, n_clusters, n_iter):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, max_iter=n_iter, random_state=120)\n",
    "    kmeans.fit(vector)\n",
    "    v_labels = kmeans.predict(vector)\n",
    "    return kmeans, v_labels\n",
    "\n",
    "kmeans, labels = clustering(data_feature, K_CLUSTERS, K_ITERS)\n",
    "#associate each word with its label\n",
    "c = list(zip(labels, data_str))\n",
    "\n",
    "cluster = defaultdict(set)\n",
    "for idc, word in c:\n",
    "    cluster[idc].add(word)\n",
    "\n",
    "# show clusters\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = make_features(messages, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# initialize list of lists \n",
    "data = [[idc, sentences[word]] for idc,word in c]\n",
    "  \n",
    "# Create the pandas DataFrame \n",
    "df = pd.DataFrame(data, columns = ['category', 'text_desc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df,field,training_data,testing_data,type=\"binary\"):\n",
    "    \"\"\"Extract features using different methods\"\"\"\n",
    "    \n",
    "    logging.info(\"Extracting features and creating vocabulary...\")\n",
    "    \n",
    "    if \"binary\" in type:\n",
    "        \n",
    "        # BINARY FEATURE REPRESENTATION\n",
    "        cv= CountVectorizer(binary=True, max_df=0.95)\n",
    "        cv.fit_transform(training_data[field].values)\n",
    "        \n",
    "        train_feature_set=cv.transform(training_data[field].values)\n",
    "        test_feature_set=cv.transform(testing_data[field].values)\n",
    "        \n",
    "        return train_feature_set,test_feature_set,cv\n",
    "  \n",
    "    elif \"counts\" in type:\n",
    "        \n",
    "        # COUNT BASED FEATURE REPRESENTATION\n",
    "        cv= CountVectorizer(binary=False, max_df=0.95)\n",
    "        cv.fit_transform(training_data[field].values)\n",
    "        \n",
    "        train_feature_set=cv.transform(training_data[field].values)\n",
    "        test_feature_set=cv.transform(testing_data[field].values)\n",
    "        \n",
    "        return train_feature_set,test_feature_set,cv\n",
    "    \n",
    "    else:    \n",
    "        \n",
    "        # TF-IDF BASED FEATURE REPRESENTATION\n",
    "        tfidf_vectorizer=TfidfVectorizer(use_idf=True, max_df=0.95)\n",
    "        tfidf_vectorizer.fit_transform(training_data[field].values)\n",
    "        \n",
    "        train_feature_set=tfidf_vectorizer.transform(training_data[field].values)\n",
    "        test_feature_set=tfidf_vectorizer.transform(testing_data[field].values)\n",
    "        \n",
    "        return train_feature_set,test_feature_set,tfidf_vectorizer\n",
    "\n",
    "def get_top_k_predictions(model,X_test,k):\n",
    "    \n",
    "    # get probabilities instead of predicted labels, since we want to collect top 3\n",
    "    probs = model.predict_proba(X_test)\n",
    "\n",
    "    # GET TOP K PREDICTIONS BY PROB - note these are just index\n",
    "    best_n = np.argsort(probs, axis=1)[:,-k:]\n",
    "    \n",
    "    # GET CATEGORY OF PREDICTIONS\n",
    "    preds=[[model.classes_[predicted_cat] for predicted_cat in prediction] for prediction in best_n]\n",
    "    \n",
    "    preds=[ item[::-1] for item in preds]\n",
    "    \n",
    "    return preds\n",
    "\n",
    "def train_model(df,field=\"text_desc\",feature_rep=\"binary\",top_k=3):\n",
    "    \n",
    "    logging.info(\"Starting model training...\")\n",
    "    \n",
    "    # GET A TRAIN TEST SPLIT (set seed for consistent results)\n",
    "    training_data, testing_data = train_test_split(df,random_state = 2000,)\n",
    "\n",
    "    # GET LABELS\n",
    "    Y_train=training_data['category'].values\n",
    "    Y_test=testing_data['category'].values\n",
    "     \n",
    "    # GET FEATURES\n",
    "    X_train,X_test,feature_transformer=extract_features(df,field,training_data,testing_data,type=feature_rep)\n",
    "\n",
    "    # INIT LOGISTIC REGRESSION CLASSIFIER\n",
    "    logging.info(\"Training a Logistic Regression Model...\")\n",
    "    scikit_log_reg = LogisticRegression(verbose=1, solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000)\n",
    "    model=scikit_log_reg.fit(X_train,Y_train)\n",
    "\n",
    "    # GET TOP K PREDICTIONS\n",
    "    preds=get_top_k_predictions(model,X_test,top_k)\n",
    "    \n",
    "    # GET PREDICTED VALUES AND GROUND TRUTH INTO A LIST OF LISTS - for ease of evaluation\n",
    "    eval_items=collect_preds(Y_test,preds)\n",
    "    \n",
    "    # GET EVALUATION NUMBERS ON TEST SET -- HOW DID WE DO?\n",
    "    logging.info(\"Starting evaluation...\")\n",
    "    accuracy=compute_accuracy(eval_items)\n",
    "    mrr_at_k=compute_mrr_at_k(eval_items)\n",
    "    \n",
    "    logging.info(\"Done training and evaluation.\")\n",
    "    \n",
    "    return model,feature_transformer,accuracy,mrr_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scikit_log_reg = LogisticRegression(verbose=1, solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000)\n",
    "classifier=scikit_log_reg.fit(vectors,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reciprocal_rank(true_labels: list, machine_preds: list):\n",
    "    \"\"\"Compute the reciprocal rank at cutoff k\"\"\"\n",
    "    \n",
    "    # add index to list only if machine predicted label exists in true labels\n",
    "    tp_pos_list = [(idx + 1) for idx, r in enumerate(machine_preds) if r in true_labels]\n",
    "\n",
    "    rr = 0\n",
    "    if len(tp_pos_list) > 0:\n",
    "        # for RR we need position of first correct item\n",
    "        first_pos_list = tp_pos_list[0]\n",
    "        \n",
    "        # rr = 1/rank\n",
    "        rr = 1 / float(first_pos_list)\n",
    "\n",
    "    return rr\n",
    "\n",
    "def compute_mrr_at_k(items:list):\n",
    "    \"\"\"Compute the MRR (average RR) at cutoff k\"\"\"\n",
    "    rr_total = 0\n",
    "    \n",
    "    for item in items:   \n",
    "        rr_at_k = _reciprocal_rank(item[0],item[1])\n",
    "        rr_total = rr_total + rr_at_k\n",
    "        mrr = rr_total / 1/float(len(items))\n",
    "\n",
    "    return mrr\n",
    "\n",
    "def collect_preds(Y_test,Y_preds):\n",
    "    \"\"\"Collect all predictions and ground truth\"\"\"\n",
    "    \n",
    "    pred_gold_list=[[[Y_test[idx]],pred] for idx,pred in enumerate(Y_preds)]\n",
    "    return pred_gold_list\n",
    "             \n",
    "def compute_accuracy(eval_items:list):\n",
    "    correct=0\n",
    "    total=0\n",
    "    \n",
    "    for item in eval_items:\n",
    "        true_pred=item[0]\n",
    "        machine_pred=set(item[1])\n",
    "        \n",
    "        for cat in true_pred:\n",
    "            if cat in machine_pred:\n",
    "                correct+=1\n",
    "                break\n",
    "    \n",
    "    \n",
    "    accuracy=correct/float(len(eval_items))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field='text_desc'\n",
    "feature_rep='tfidf'\n",
    "top_k=3\n",
    "\n",
    "model,transformer,accuracy,mrr_at_k=train_model(df,field='text_desc',feature_rep=feature_rep,top_k=top_k)\n",
    "print(\"\\nAccuracy={0}; MRR={1}\".format(accuracy,mrr_at_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
