{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "* Load corpus.\n",
    "* Load corpus features, clusters ids list, labels of each cluster.\n",
    "* Prepared data to train the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ipynb.fs.full.logistic_regression_functions import *\n",
    "from ipynb.fs.full.pre_processing_functions import process_sentence\n",
    "from ipynb.fs.full import paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data, original_data = load_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get features of corpus and labels from kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Features to train the classifier.\n",
    "data_feature = pd.read_pickle(paths.DF_PATH)\n",
    "# Ids of the cluster for each sentence.\n",
    "cluster_ids = pd.read_pickle(paths.IDS_CLUSTER_PATH)\n",
    "# Classes for the classifier.\n",
    "with open(paths.CLUSTER_LABELS_PATH, 'r') as file:\n",
    "    labels = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data to train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# join vectors and labels\n",
    "text_label = [[data_feature.loc[ind].values, cluster_ids.loc[ind,0]] for ind in range(0,len(data_feature))]\n",
    "\n",
    "# create DataFrame\n",
    "df = pd.DataFrame(text_label, columns = ['text','label'])\n",
    "\n",
    "data_as_str = [' '.join(x) for x in data]\n",
    "\n",
    "text_as_str_label = [[data_as_str[ind], cluster_ids.loc[ind,0]] for ind in range(0, len(data_feature))]\n",
    "df_with_str = pd.DataFrame(text_as_str_label, columns = ['text','label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model with function 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "field='text'\n",
    "top_k=3\n",
    "\n",
    "model,accuracy,mrr_at_k=train_model(df)\n",
    "print(\"\\nAccuracy={0}; MRR={1}\".format(accuracy,mrr_at_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model with function 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field='text'\n",
    "top_k=3\n",
    "feature_rep = 'binary' #binary, counts, tf-idf \n",
    "\n",
    "model, feature_transformer, accuracy, mrr = train_model_with_transformer(df_with_str, feature_rep=feature_rep)\n",
    "print(\"\\nAccuracy={0}; MRR={1}\".format(accuracy,mrr_at_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\n",
    "    'Hola vamos a comprar dolares pesos bonos lo que dinero',\n",
    "    'Che a la tarde voy a tu casa a tomar unos mates y estudiamos para el parcial',\n",
    "    'Feliz cumplea√±os numero 100 Martin , espero que pases un lindo dia ahi en el PAMI',\n",
    "    'Hola tio , estamos pensando para este fin de semana comer un asado en la casa de los abuelos , nos vemos alla',\n",
    "    'Antes de irme , tengo que presentar todos los documentos para sacar la visa de trabajo , me piden un monton de certificados',\n",
    "]\n",
    "\n",
    "for sample in samples:\n",
    "    test_features = feature_transformer.transform(process_sentence(sample))\n",
    "    labels_ind = get_top_k_predictions(model, test_features, 2)\n",
    "    print('Sample: ', sample)\n",
    "    print('Los labels para este ejemplo son:', [labels[x] for x in labels_ind[0]])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model and transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we need to save both the transformer and model \n",
    "# transformer to encode/vectorize per our settings\n",
    "# model to predict\n",
    "pickle.dump(model,open(paths.CLASSIFIER_MODEL_PATH, 'wb'))\n",
    "pickle.dump(feature_transformer,open(paths.TRANSFORMER_PATH,'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
