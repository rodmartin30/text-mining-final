{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "from spacy_spanish_lemmatizer import SpacyCustomLemmatizer\n",
    "\n",
    "\n",
    "# =================== CONSTANTS ===================\n",
    "SPACE = ' '\n",
    "COLON = ':'\n",
    "DASH = '-'\n",
    "DOT = '.'\n",
    "\n",
    "UNIT_THRESHOLD = 5\n",
    "TIME_THRESHOLD = 600\n",
    "MIN_WORD_LENGTH = 3\n",
    "\n",
    "LANGUAGE = 'es'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNIT CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "class Unit:\n",
    "    def __init__(self, dt, sender, message):\n",
    "        self.dt = self.get_datetime(dt)\n",
    "        self.sender = sender\n",
    "        self.message = message\n",
    "    \n",
    "    def same_sender(self, sender):\n",
    "        return self.sender == sender\n",
    "    \n",
    "    def add_text(self, text):\n",
    "        self.message += '. '.join([text])\n",
    "    \n",
    "    def set_dt(self, dt):\n",
    "        self.dt = dt\n",
    "    \n",
    "    def timedelta(self, dt):\n",
    "        if self.dt > dt:\n",
    "            return (self.dt-dt).seconds\n",
    "        return (dt-self.dt).seconds\n",
    "\n",
    "    def get_datetime(self, dt):\n",
    "        date, time = dt.split(',')\n",
    "        month, day, year = date.split('/')\n",
    "        hour, minutes = time.split(':')\n",
    "        year = 2000 + int(year)\n",
    "        return datetime.datetime(year, int(month), int(day), int(hour), int(minutes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET_CORPUS AND PRE_PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = [\n",
    "    [r'(\\w)\\1{2,}',r'\\1'],\n",
    "    [r'qu\\w',''],\n",
    "    [r'no\\w','no'],\n",
    "    [\"jaj[ja]+\",\"\"],\n",
    "    [\"mñna\", \"mañana\"],\n",
    "    [\"cba\", \"Cordoba\"],\n",
    "    [\"si[si]+\", \"si\"]\n",
    "]\n",
    "replace = {\n",
    "    \"hno\": \"hermano\",\n",
    "    \"hdp\": \"insulto\",\n",
    "    \"dpto\": \"departamento\",\n",
    "    \n",
    "    'a':'',\n",
    "    'y':'',\n",
    "    'o':'',\n",
    "    'dale':'',\n",
    "    'hola':'',\n",
    "    'ok':'',\n",
    "    'oka':'',\n",
    "    'ver':'',\n",
    "    'estar':'',\n",
    "    'decir':'',\n",
    "    'pasar':'',\n",
    "    'che':'',\n",
    "    'ya':'',\n",
    "    'yaa':'',\n",
    "    'eia':'',\n",
    "    'meno':'',\n",
    "    'message':'',\n",
    "    'deleted':'',\n",
    "    'you':'',\n",
    "    '<media omitted>':''\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus(corpus_filepath):\n",
    "    # Get text.\n",
    "    with open(corpus_filepath) as f:\n",
    "        lines = f.read().lower()\n",
    "    lines = lines.split('\\n')\n",
    "    corpus = []\n",
    "    # Get list of Units.\n",
    "    # Format of lines: date, time - sender: message\n",
    "    for line in lines:\n",
    "        unit = line.split(DASH)\n",
    "        if len(unit) > 1:\n",
    "            for exp in reg:\n",
    "                unit[1] = re.sub(exp[0],exp[1],unit[1])\n",
    "            if len(unit[0].split(',')) > 1 and len(unit[1].split(COLON)) > 1:\n",
    "                unit = Unit(unit[0],unit[1].split(COLON)[0], unit[1].split(COLON)[1])\n",
    "                if len(corpus) > 0 and corpus[-1].same_sender(unit.sender) and \\\n",
    "                    corpus[-1].timedelta(unit.dt) < TIME_THRESHOLD:\n",
    "                        corpus[-1].add_text(unit.message)\n",
    "                        corpus[-1].set_dt(unit.dt)\n",
    "                else:\n",
    "                    corpus.append(unit)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(corpus_filepath):\n",
    "    corpus = get_corpus(corpus_filepath)\n",
    "    # Skip units which has less than UNIT_THRESHOLD words.\n",
    "    senders = []\n",
    "    messages = []\n",
    "    original_messages = []\n",
    "    nlp = spacy.load(LANGUAGE)\n",
    "    # Add lemmatizer from https://github.com/pablodms/spacy-spanish-lemmatizer\n",
    "    lemmatizer = SpacyCustomLemmatizer()\n",
    "    nlp.add_pipe(lemmatizer, name=\"lemmatizer\", after=\"tagger\")\n",
    "    print('Number of units {}',len(corpus))\n",
    "    for unit in corpus:\n",
    "        senders.append(unit.sender)\n",
    "        message = nlp(unit.message)\n",
    "        process_words = []\n",
    "        for word in message:\n",
    "            # Remove non alpha words and make words lower with lemmatization or stop words.\n",
    "            if not word.text.isalpha or word.is_stop:\n",
    "                continue\n",
    "            word = word.lemma_.lower()\n",
    "            # Remove or replace specific words.\n",
    "            if word in replace:\n",
    "                word = replace[word]\n",
    "            # Remove words with less than 3 characters.\n",
    "            if len(word) < MIN_WORD_LENGTH:\n",
    "                continue\n",
    "            process_words.append(word)\n",
    "        if len(process_words) < UNIT_THRESHOLD:\n",
    "            continue\n",
    "        original_messages.append(unit.message)\n",
    "        messages.append(process_words)\n",
    "    return messages, original_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
