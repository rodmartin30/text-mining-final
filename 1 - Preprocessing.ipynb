{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from ipynb.fs.full.pre_processing_functions import pre_processing\n",
    "\n",
    "WORD_TIMES = 7\n",
    "PHRASE_SIZE = 5\n",
    "\n",
    "TXT_FILES_PATH = \"/Users/rodmartin/textmining/text-mining/dialog-tagging/data/*.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "len unit 492\n",
      "1\n",
      "len unit 2683\n",
      "2\n",
      "len unit 171\n",
      "3\n",
      "len unit 79\n",
      "4\n",
      "len unit 44\n",
      "5\n",
      "len unit 13\n",
      "6\n",
      "len unit 12\n",
      "7\n",
      "len unit 462\n",
      "8\n",
      "len unit 1517\n",
      "9\n",
      "len unit 7542\n",
      "10\n",
      "len unit 393\n",
      "11\n",
      "len unit 776\n",
      "12\n",
      "len unit 2760\n",
      "13\n",
      "len unit 401\n",
      "14\n",
      "len unit 8345\n",
      "15\n",
      "len unit 40\n",
      "16\n",
      "len unit 922\n",
      "17\n",
      "len unit 25\n",
      "18\n",
      "len unit 849\n",
      "19\n",
      "len unit 1237\n",
      "20\n",
      "len unit 16\n",
      "21\n",
      "len unit 963\n",
      "22\n",
      "len unit 1806\n",
      "23\n",
      "len unit 1366\n",
      "24\n",
      "len unit 171\n",
      "25\n",
      "len unit 52\n"
     ]
    }
   ],
   "source": [
    "txt_files = glob.glob(TXT_FILES_PATH)\n",
    "\n",
    "pre_data = []\n",
    "data = []\n",
    "\n",
    "file_n = 0\n",
    "for file_path in txt_files:\n",
    "    print(\"Processing file number: {}\".format(file_n))\n",
    "    file_n += 1\n",
    "    message, original_message = pre_processing(file_path)\n",
    "    data += message\n",
    "    pre_data += original_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove specifict words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed = {\n",
    "    'omitted':'',\n",
    "    'jeje':'',\n",
    "    'ero':'',\n",
    "    'vos':'',\n",
    "    '..':'',\n",
    "    '...':'',\n",
    "    '....':'',\n",
    "    '.....':'',\n",
    "    'media':'',\n",
    "    'location':'',\n",
    "    'missed':''\n",
    "    \n",
    "}\n",
    "new_data = []\n",
    "for phrase in data:\n",
    "    new_phrase = []\n",
    "    for word in phrase:\n",
    "        if word in removed:\n",
    "            continue\n",
    "        new_phrase.append(word)\n",
    "    new_data.append(new_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove words with less than WORD_TIMES apparitions in corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for phrase in data:\n",
    "    words += phrase\n",
    "\n",
    "distribution_words = Counter(words)\n",
    "data = [[word for word in phrase if distribution_words[word] > WORD_TIMES ] for phrase in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove phrases with less than PHRASE_SIZE words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(data)):\n",
    "    if len(data[i]) < PHRASE_SIZE:\n",
    "        data[i] = []\n",
    "        pre_data[i] = []\n",
    "\n",
    "data = [phrase for phrase in data if phrase != []]\n",
    "pre_data = [phrase for phrase in pre_data if phrase != []]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dumping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/text2corpus/corpus_messages.txt', 'wb') as f:\n",
    "    pickle.dump(data, f)\n",
    "with open('data/text2corpus/corpus_original_messages.txt', 'wb') as f:\n",
    "    pickle.dump(pre_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
