{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from ipynb.fs.full.pre_processing_functions import pre_processing\n",
    "from ipynb.fs.full.logistic_regression_functions import get_top_k_predictions\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_PATH = \"models/model.pkl\"\n",
    "TRANSFORMER_PATH = \"models/transformer.pkl\"\n",
    "\n",
    "FASTTEXT_MODEL_PATH = 'models/fasttext_15_5_200.pkl'\n",
    "DEMO_TXT_PATH = \"/Users/rodmartin/text-mining-final/data/demo.txt\"\n",
    "LABELS_PATH = \"data/labels_kmeans\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model, transformer and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CLASSIFIER_PATH, 'rb') as file:\n",
    "    classifier = pickle.load(file)\n",
    "with open(TRANSFORMER_PATH, 'rb') as file:\n",
    "    feature_transformer = pickle.load(file)\n",
    "\n",
    "# Load Fasttext model\n",
    "fasttext_model = FastText.load(FASTTEXT_MODEL_PATH)\n",
    "\n",
    "with open(LABELS_PATH, 'r') as file:\n",
    "    labels_str = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lindar, montón, comer', 'salir, casar, llegar', 'besar, abrazar, enome', 'creer, dolar, peso', 'unir, parir, tomar', 'creer, volver, parir', 'parir, comer, andar', 'creer, parir, comer', 'cocinar, mañana, parir', 'was, this, message', '']\n"
     ]
    }
   ],
   "source": [
    "# Make labels_str a list of labels.\n",
    "labels_str = labels_str.split('\\n')\n",
    "print(labels_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEMO TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of units {} 1\n"
     ]
    }
   ],
   "source": [
    "# Step 1 is get the chat txt and do a pre processing of it.\n",
    "message, original_message = pre_processing(DEMO_TXT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mensaje original:\n",
      "\n",
      " ¡hola tincho! cómo andas? che en física, me dijo eze  vos hiciste los prácticos y conforme los ibas haciendo ibas consultando al teórico. el final lo rendiste libre? solo te tomaron práctico? cuánto tiempo total le dedicaste? gracias!\n",
      "\n",
      "Mensaje preprocesado:\n",
      "\n",
      "[['tincho', 'andas', 'física', 'eze', 'vos', 'hacer', 'práctico', 'conforme', 'ibas', 'ibas', 'consultar', 'teórico', 'rendir', 'libre', 'tomar', 'práctico', 'dedicar', 'gracia']]\n"
     ]
    }
   ],
   "source": [
    "print('Mensaje original:\\n')\n",
    "for sentence in original_message:\n",
    "    print(sentence)\n",
    "\n",
    "print('\\nMensaje preprocesado:\\n')\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 is to get the features of the current conversations.\n",
    "list_messages = [' '.join(x) for x in message]\n",
    "features = feature_transformer.transform(list_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 is to give to the model the features of the conversations and get predictions.\n",
    "result = get_top_k_predictions(classifier, features, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones:\n",
      "\n",
      "lindar, montón, comer\n",
      "unir, parir, tomar\n",
      "besar, abrazar, enome\n"
     ]
    }
   ],
   "source": [
    "# Step 4 is see what were the predictions of the model.\n",
    "result_with_labels = [labels_str[x] for x in result[0]]\n",
    "print('Predicciones:\\n')\n",
    "for x in result_with_labels:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
