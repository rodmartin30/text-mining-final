{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "# =================== CONSTANTS ===================\n",
    "SPACE = ' '\n",
    "COLON = ':'\n",
    "DASH = '-'\n",
    "DOT = '.'\n",
    "\n",
    "UNIT_THRESHOLD = 5\n",
    "TIME_THRESHOLD = 600\n",
    "\n",
    "LANGUAGE = 'es'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNIT CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "class Unit:\n",
    "    def __init__(self, dt, sender, message):\n",
    "        self.dt = self.get_datetime(dt)\n",
    "        self.sender = sender\n",
    "        self.message = message\n",
    "    \n",
    "    def same_sender(self, sender):\n",
    "        return self.sender == sender\n",
    "    \n",
    "    def add_text(self, text):\n",
    "        self.message += '. '.join([text])\n",
    "    \n",
    "    def set_dt(self, dt):\n",
    "        self.dt = dt\n",
    "    \n",
    "    def timedelta(self, dt):\n",
    "        if self.dt > dt:\n",
    "            return (self.dt-dt).seconds\n",
    "        return (dt-self.dt).seconds\n",
    "\n",
    "    def get_datetime(self, dt):\n",
    "        date, time = dt.split(',')\n",
    "        month, day, year = date.split('/')\n",
    "        hour, minutes = time.split(':')\n",
    "        year = 2000 + int(year)\n",
    "        return datetime.datetime(year, int(month), int(day), int(hour), int(minutes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET_CORPUS AND PRE_PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = [\n",
    "    [r'(\\w)\\1{2,}',r'\\1'],\n",
    "    [r'qu\\w',''],\n",
    "    [r'no\\w','no'],\n",
    "    [\"jaj[ja]+\",\"\"],\n",
    "    [\"<media omitted>\", \"\"],\n",
    "    [\"mñna\", \"mañana\"],\n",
    "    [\"cba\", \"Cordoba\"],\n",
    "    [\"si[si]+\", \"si\"],\n",
    "    [\"hno\", \"hermano\"],\n",
    "    [\"hdp\", \"insulto\"],\n",
    "    [\"dpto\", \"departamento\"]\n",
    "]\n",
    "STOP_WORDS = {\"a\",\"y\", \"o\", \"dale\", \"hola\", \\\n",
    "              \"ok\", \"oka\", \"ver\", \"estar\", \\\n",
    "              \"decir\", \"pasar\", \"che\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus(corpus_filepath):\n",
    "    # Get text.\n",
    "    with open(corpus_filepath) as f:\n",
    "        lines = f.read().lower()\n",
    "    lines = lines.split('\\n')\n",
    "    corpus = []\n",
    "    # Get list of Units.\n",
    "    # Format of lines: date, time - sender: message\n",
    "    for line in lines:\n",
    "        unit = line.split(DASH)\n",
    "        if len(unit) > 1:\n",
    "            for exp in reg:\n",
    "                unit[1] = re.sub(exp[0],exp[1],unit[1])\n",
    "            if len(unit[0].split(',')) > 1 and len(unit[1].split(COLON)) > 1:\n",
    "                unit = Unit(unit[0],unit[1].split(COLON)[0], unit[1].split(COLON)[1])\n",
    "                # Messages with no less than UNIT_THRESHOLD\n",
    "                ''' TODO: Make experimentation with this\n",
    "                    if len(unit.message.split(SPACE)) < UNIT_THRESHOLD:\n",
    "                    continue\n",
    "                '''\n",
    "                if len(corpus) > 0 and corpus[-1].same_sender(unit.sender) and \\\n",
    "                    corpus[-1].timedelta(unit.dt) < TIME_THRESHOLD:\n",
    "                        corpus[-1].add_text(unit.message)\n",
    "                        corpus[-1].set_dt(unit.dt)\n",
    "                else:\n",
    "                    corpus.append(unit)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(corpus_filepath):\n",
    "    corpus = get_corpus(corpus_filepath)\n",
    "    # Skip units which has less than UNIT_THRESHOLD words.\n",
    "    senders = []\n",
    "    messages = []\n",
    "    original_messages = []\n",
    "    nlp = spacy.load(LANGUAGE)\n",
    "    nlp.Defaults.stop_words|= STOP_WORDS\n",
    "    for unit in corpus:\n",
    "        senders.append(unit.sender)\n",
    "        message = nlp(unit.message)\n",
    "        # Remove non alpha words and make words lower with lemmatization.\n",
    "        words = [word.lemma_.lower() for word in message if word.is_alpha]\n",
    "        # Remove stop words.\n",
    "        message = nlp(' '.join(words))\n",
    "        words = [word.text for word in message if not word.is_stop]\n",
    "        # Remove words with less than 3 characters.\n",
    "        words = [word for word in words if len(word.strip()) > 2]\n",
    "        if len(words) < UNIT_THRESHOLD:\n",
    "            continue\n",
    "        original_messages.append(unit.message)\n",
    "        messages.append(words)\n",
    "    return messages, original_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
